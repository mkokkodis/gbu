{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Implementation details and runtime comparisons\n",
    "\n",
    "- Author: Marios Kokkodis\n",
    "- email: marios.kokkodis@gmail.com \n",
    "\n",
    "> Python notes: tested on PY38\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "if '../python/' not in sys.path: sys.path.insert(1, '../python/')\n",
    "import time\n",
    "from hmm_gbu import HMM\n",
    "from custom_util_functions import do_feature_selection, run_logistic, get_auc_per_class, print_border_line\n",
    "from custom_util_functions import  prepare_hmm_matrix, run_forest, run_xg, run_svm, get_model_key\n",
    "from sklearn.pipeline import Pipeline\n",
    "from hmm_functions import transform_input_to_HMM_timelines,createPriors,init_params\n",
    "from sklearn import linear_model, svm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', 'Solver terminated early.*')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "from joblib import dump, load\n",
    "\n",
    "\n",
    "\n",
    "emission_variables = [ 'curRating','numberOfReviewsRest',\n",
    "                'cheap','affordable','expensive','qualityOfRestaurantsVisited','focalUserReviews']\n",
    "transition_variables = ['focalUserReviews']\n",
    "transition_index = transition_variables.index('focalUserReviews')\n",
    "fold = 0\n",
    "dataset = 'restaurant_ncv.csv'\n",
    "employer_id = 'user'\n",
    "task_id = 'choicesetId'\n",
    "application_id = 'application'\n",
    "d = pd.read_csv(\"../../data/\"+dataset)\n",
    "d = d.sort_values([employer_id, 'daysTrend', task_id])\n",
    "pipe = Pipeline([('imputer', SimpleImputer(missing_values=np.nan, strategy=\"median\",add_indicator=False)),\n",
    "                 ('scaler',MinMaxScaler())])\n",
    "train = d[d['set_annotation'].str.contains(pat =('train_'+str(fold))+',|train_'+str(fold)+\"$\", regex=True)==True].copy()\n",
    "validation = d[d['set_annotation'].str.contains(pat =('validation_'+str(fold))+',|validation_'+str(fold)+\"$\",\n",
    "                                                regex=True)==True].copy()\n",
    "trainedPipeline = pipe.fit(train[emission_variables])\n",
    "trainTransformed = pd.DataFrame(data=trainedPipeline.transform(train[emission_variables]),\n",
    "             index = None,  columns=emission_variables)\n",
    "validation_transformed = pd.DataFrame(data=trainedPipeline.transform(validation[emission_variables]),\n",
    "             index = None,  columns=emission_variables)\n",
    "trainTransformed['set_annotation'] = 'train'\n",
    "validation_transformed['set_annotation'] = 'validation'\n",
    "train_y = train['Y_it']\n",
    "validation_y = validation['Y_it']\n",
    "transition_application_employer_train = prepare_hmm_matrix(trainTransformed[transition_variables],\n",
    "                                                               train[application_id],\n",
    "                                                               train[employer_id])\n",
    "transition_application_employer_validation = prepare_hmm_matrix(validation_transformed[transition_variables],\n",
    "                                                              validation[application_id],\n",
    "                                                              validation[employer_id])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Different solvers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### COBYLA - 100 iterations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "Note: The HMM assumes ranked timelines as inputs\n",
      "-----------------------------------------------------\n",
      "fit() was called...\n",
      "Transforming input matrix to HMM sequences...\n",
      "Total number of parameters to be estimated: 92\n",
      "\t> minimized ll: 803\n",
      "--- 5.744 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model = HMM(transition_application_employer_train, transition_application_employer_validation, transition_index,\n",
    "                     iterations=100,  states=4,\n",
    "            verbal=True, solver = 'COBYLA')\n",
    "Z_timelines = trainTransformed[emission_variables].to_numpy()\n",
    "r = model.fit(Z_timelines, train_y.to_numpy())\n",
    "print(\"\\t> minimized ll:\", round(r.optimization_result.fun))\n",
    "print(\"--- %.3f seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "#### COBYLA - 1000 iterations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "Note: The HMM assumes ranked timelines as inputs\n",
      "-----------------------------------------------------\n",
      "fit() was called...\n",
      "Transforming input matrix to HMM sequences...\n",
      "Total number of parameters to be estimated: 92\n",
      "\t> minimized ll: 446\n",
      "--- 56.889 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model = HMM(transition_application_employer_train, transition_application_employer_validation, transition_index,\n",
    "                     iterations=1000,  states=4,\n",
    "            verbal=True, solver = 'COBYLA')\n",
    "Z_timelines = trainTransformed[emission_variables].to_numpy()\n",
    "r = model.fit(Z_timelines, train_y.to_numpy())\n",
    "print(\"\\t> minimized ll:\", round(r.optimization_result.fun))\n",
    "print(\"--- %.3f seconds ---\" % (time.time() - start_time))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### BFGS - 100 iterations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "Note: The HMM assumes ranked timelines as inputs\n",
      "-----------------------------------------------------\n",
      "fit() was called...\n",
      "Transforming input matrix to HMM sequences...\n",
      "Total number of parameters to be estimated: 92\n",
      "\t> minimized ll: 1895\n",
      "--- 297.966 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model = HMM(transition_application_employer_train, transition_application_employer_validation, transition_index,\n",
    "                     iterations=100,  states=4,\n",
    "            verbal=True, solver = 'BFGS')\n",
    "Z_timelines = trainTransformed[emission_variables].to_numpy()\n",
    "r = model.fit(Z_timelines, train_y.to_numpy())\n",
    "print(\"\\t> minimized ll:\", round(r.optimization_result.fun))\n",
    "print(\"--- %.3f seconds ---\" % (time.time() - start_time))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### L-BFGS - 100 iterations\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "Note: The HMM assumes ranked timelines as inputs\n",
      "-----------------------------------------------------\n",
      "fit() was called...\n",
      "Transforming input matrix to HMM sequences...\n",
      "Total number of parameters to be estimated: 92\n",
      "\t> minimized ll: 826\n",
      "--- 86.335 seconds ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "model = HMM(transition_application_employer_train, transition_application_employer_validation, transition_index,\n",
    "                     iterations=100,  states=4,\n",
    "            verbal=True, solver = 'L-BFGS-B')\n",
    "Z_timelines = trainTransformed[emission_variables].to_numpy()\n",
    "r = model.fit(Z_timelines, train_y.to_numpy())\n",
    "print(\"\\t> minimized ll:\", round(r.optimization_result.fun))\n",
    "print(\"--- %.3f seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convergence analysis\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Convergence test for COBYLA, BFGS, and LBFGS\n",
    "\n",
    "In the following we use a tolerance level of 0.01, and allow for 100 iterations\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "Using solver: COBYLA\n",
      "-----------------------------------------------------\n",
      "Note: The HMM assumes ranked timelines as inputs\n",
      "-----------------------------------------------------\n",
      "fit() was called...\n",
      "Transforming input matrix to HMM sequences...\n",
      "Total number of parameters to be estimated: 38\n",
      "\t> minimized ll: 476\n",
      "\t> convergence: False\n",
      "--- 5.553 seconds ---\n",
      "-----------------------------------------------------\n",
      "Using solver: BFGS\n",
      "-----------------------------------------------------\n",
      "Note: The HMM assumes ranked timelines as inputs\n",
      "-----------------------------------------------------\n",
      "fit() was called...\n",
      "Transforming input matrix to HMM sequences...\n",
      "Total number of parameters to be estimated: 38\n",
      "\t> minimized ll: 1496\n",
      "\t> convergence: True\n",
      "--- 12.423 seconds ---\n",
      "-----------------------------------------------------\n",
      "Using solver: L-BFGS-B\n",
      "-----------------------------------------------------\n",
      "Note: The HMM assumes ranked timelines as inputs\n",
      "-----------------------------------------------------\n",
      "fit() was called...\n",
      "Transforming input matrix to HMM sequences...\n",
      "Total number of parameters to be estimated: 38\n",
      "\t> minimized ll: 2698\n",
      "\t> convergence: True\n",
      "--- 17.875 seconds ---\n"
     ]
    }
   ],
   "source": [
    "for solver in ['COBYLA','BFGS','L-BFGS-B']:\n",
    "    print_border_line()\n",
    "    print(\"Using solver:\",solver)\n",
    "    start_time = time.time()\n",
    "    model = HMM(transition_application_employer_train, transition_application_employer_validation, transition_index,\n",
    "                     iterations=100,  states=2, tol = 0.01,\n",
    "            verbal=True, solver = solver\n",
    "        )\n",
    "    Z_timelines = trainTransformed[emission_variables].to_numpy()\n",
    "    r = model.fit(Z_timelines, train_y.to_numpy())\n",
    "    print(\"\\t> minimized ll:\", round(r.optimization_result.fun))\n",
    "    print(\"\\t> convergence:\",r.optimization_result.success)\n",
    "    print(\"--- %.3f seconds ---\" % (time.time() - start_time))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Complexity of likelihood estimation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Intractable raw likelihood"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total instances: 31\n"
     ]
    }
   ],
   "source": [
    "verbal=False\n",
    "np.random.seed(1234)\n",
    "states = [0,1]\n",
    "#choice sets that include all outcomes\n",
    "choice_sets = [73,   87,      78]\n",
    "print(\"Total instances:\", len(train[train.choicesetId.isin(choice_sets)]))\n",
    "trainTransformed = pd.DataFrame(data=trainedPipeline.transform(train[train.choicesetId.isin(choice_sets)][emission_variables]),\n",
    "             index = None,  columns=emission_variables)\n",
    "train_y = train[train.choicesetId.isin(choice_sets)]['Y_it']\n",
    "transition_application_employer_train = prepare_hmm_matrix(trainTransformed[transition_variables],\n",
    "                                                    train[train.choicesetId.isin(choice_sets)][application_id],\n",
    "                                                    train[train.choicesetId.isin(choice_sets)][employer_id])\n",
    "Z_timelines = trainTransformed[emission_variables].to_numpy()\n",
    "transition_model='multinomial_constrained'\n",
    "X,y = Z_timelines, train_y.to_numpy()\n",
    "emission_distro_pars = len(np.unique(y)) - 1\n",
    "(sequences_X, sequences_Z, sequences_O, applications) = transform_input_to_HMM_timelines(X, y,\n",
    "                        transition_application_employer_train,\n",
    "                                verbal,n_cores=1)\n",
    "variables_in_Z = sequences_Z[0].shape[1]\n",
    "variables_in_X = sequences_X[0].shape[1]\n",
    "# initialize parameters\n",
    "(theta_prior, transitionParameters, emissionParameters, pi) = createPriors(variables_in_X,\n",
    "                                                                                        variables_in_Z,\n",
    "                                                                                        states,\n",
    "                                                                                        transition_model,\n",
    "                                                                                        emission_distro_pars,\n",
    "                                                                                        verbal)\n",
    "\n",
    "(pi, gammaCoeffsForZ, betaCoeffsforX,\n",
    "     sigmaPars) = init_params(theta_prior, variables_in_Z, states,\n",
    "                                                emission_distro_pars, variables_in_X,\n",
    "                                                transition_model)\n",
    "\n",
    "zCoeffsMat = []\n",
    "for state in states:\n",
    "    zCoeffsMat.append([])\n",
    "    for symbol in range(emission_distro_pars + 1):  # number of symbols for multinomial emissions.\n",
    "        zCoeffsMat[state].append(gammaCoeffsForZ[state][symbol])\n",
    "zCoeffsMat = np.array(zCoeffsMat)\n",
    "\n",
    "xCoeffsMat = []\n",
    "for stateFrom in states:\n",
    "    xCoeffsMat.append([])\n",
    "    for stateTO in states:\n",
    "        xCoeffsMat[stateFrom].append(betaCoeffsforX[stateFrom][stateTO])\n",
    "xCoeffsMat = np.array(xCoeffsMat)\n",
    "\n",
    "from importlib import reload\n",
    "import hmm_functions\n",
    "reload(hmm_functions)\n",
    "from hmm_functions import transform_input_to_HMM_timelines, createPriors, init_params, get_individual_log_l\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.9416770404861435e-19\n",
      "2.988449887486522e-08\n",
      "Negative L naive: 59.003\n",
      "--- 1037.36 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#Returns the likelihood function by explicitly estimating the sums/products\n",
    "L = 0\n",
    "#sequences_X, sequences_Z, sequences_O\n",
    "for i in range(len(sequences_X)):\n",
    "    client_X = sequences_X[i]\n",
    "    client_O = sequences_O[i]\n",
    "    client_Z = sequences_Z[i]\n",
    "    L-= get_individual_log_l(client_X,client_Z,client_O,\n",
    "                            zCoeffsMat,None,transition_index,transition_model,\n",
    "                            states,xCoeffsMat,pi)\n",
    "print(\"Negative L naive: %.3f\" %(L))\n",
    "print(\"--- %.2f seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# %%"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Vectorization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative L numpy: 59.00\n",
      "--- 0.001 seconds ---\n"
     ]
    }
   ],
   "source": [
    "reload(hmm_functions)\n",
    "from hmm_functions import get_likelihood_validation\n",
    "start_time = time.time()\n",
    "L= get_likelihood_validation(sequences_X,sequences_Z,sequences_O,pi,xCoeffsMat,zCoeffsMat,\n",
    "                          transition_model,states,transition_index)\n",
    "print(\"Negative L numpy: %.2f\" %(L))\n",
    "print(\"--- %.3f seconds ---\" % (time.time() - start_time))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Comparison with LSTM"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\r\n",
      "Note: The HMM assumes ranked timelines as inputs\r\n",
      "-----------------------------------------------------\r\n",
      "fit() was called...\r\n",
      "Transforming input matrix to HMM sequences...\r\n",
      "Total number of parameters to be estimated: 63\r\n",
      "Minimized ll: 2783\r\n",
      "predict_proba() was called...\r\n",
      "Transforming input matrix to HMM sequences...\r\n",
      "-----------------------------------------------------\r\n",
      "\tFinal AUC score on Hire-positive: 0.56605\r\n",
      "-----------------------------------------------------\r\n",
      "--- 98.163 seconds ---\r\n"
     ]
    }
   ],
   "source": [
    "!python ../python/test_speed.py"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\r\n",
      "2021-03-05 20:09:47.294379: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n",
      "2021-03-05 20:09:47.294547: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n",
      "2021-03-05 20:09:47.446208: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\r\n",
      "-----------------------------------------------------\r\n",
      "\t(Final AUC score on Hire-positive: 0.531 )\r\n",
      "-----------------------------------------------------\r\n",
      "--- 125.947 seconds ---\r\n"
     ]
    }
   ],
   "source": [
    "!python ../python/test_speed_lstm.py -C\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
